{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "wCH7GPScqz-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-crf -i https://pypi.tuna.tsinghua.edu.cn/simple/"
      ],
      "metadata": {
        "id": "MkByKXMZs-pc",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkeeN7xoirZM"
      },
      "outputs": [],
      "source": [
        "# Named Entity Recognition with BERT + BiLSTM + CRF\n",
        "# Homework 3\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import seaborn as sns\n",
        "\n",
        "# Set environment variables to help with CUDA debugging\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "\n",
        "# Force CPU or GPU\n",
        "FORCE_CPU = False  # Set to False to enable GPU\n",
        "\n",
        "# Check and install required packages\n",
        "required_packages = {\n",
        "    'transformers': 'transformers',\n",
        "    'torchcrf': 'pytorch-crf',\n",
        "}\n",
        "\n",
        "# Check if necessary packages are installed\n",
        "for module_name, package_name in required_packages.items():\n",
        "    try:\n",
        "        __import__(module_name)\n",
        "    except ImportError:\n",
        "        print(f\"Package {module_name} is required. Please run:\")\n",
        "        print(f\"pip install {package_name}\")\n",
        "        print(\"Then run this program again\")\n",
        "        sys.exit(1)\n",
        "\n",
        "# Import necessary modules\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torchcrf import CRF\n",
        "\n",
        "# Check if GPU is available\n",
        "if FORCE_CPU:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"Using CPU as specified\")\n",
        "else:\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            # Test CUDA functionality\n",
        "            test_tensor = torch.tensor([1.0]).cuda()\n",
        "            test_tensor = test_tensor + 1.0\n",
        "            device = torch.device('cuda')\n",
        "            print(f\"CUDA is available and working. Using device: {device}\")\n",
        "            print(f\"CUDA Version: {torch.version.cuda}\")\n",
        "            print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        else:\n",
        "            device = torch.device('cpu')\n",
        "            print(f\"CUDA not available. Using device: {device}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing CUDA: {e}\")\n",
        "        print(\"Falling back to CPU\")\n",
        "        device = torch.device('cpu')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "try:\n",
        "    torch.manual_seed(42)\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.manual_seed_all(42)\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not set CUDA random seed: {e}\")\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "# Define dataset file paths\n",
        "TRAIN_FILE = \"train.txt\"\n",
        "VALID_FILE = \"valid.txt\"\n",
        "TEST_FILE = \"test.txt\"\n",
        "\n",
        "# Parameters\n",
        "MAX_LEN = 128  # Maximum sequence length\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "EPOCHS = 10\n",
        "MODEL_NAME = \"bert-base-cased\"  # Use standard BERT model\n",
        "\n",
        "# Load tokenizer\n",
        "print(f\"Loading tokenizer for pretrained model '{MODEL_NAME}'...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "print(\"Tokenizer loaded successfully\")\n",
        "\n",
        "# Function to read CoNLL format NER data\n",
        "def read_conll(file_path):\n",
        "    \"\"\"Read file in CoNLL format with special handling for malformed lines\"\"\"\n",
        "    sentences = []\n",
        "    labels = []\n",
        "\n",
        "    sentence = []\n",
        "    label = []\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line == \"\":\n",
        "                if sentence:\n",
        "                    sentences.append(sentence)\n",
        "                    labels.append(label)\n",
        "                    sentence = []\n",
        "                    label = []\n",
        "            else:\n",
        "                # Split by whitespace\n",
        "                parts = line.split()\n",
        "\n",
        "                # Special handling for malformed lines\n",
        "                if len(parts) == 1:\n",
        "                    # This might be a line with just a tag (like 'O')\n",
        "                    # Skip this line, don't show warning\n",
        "                    continue\n",
        "                elif len(parts) >= 2:\n",
        "                    # Normal case: we have at least a token and a tag\n",
        "                    word = parts[0]\n",
        "                    tag = parts[-1]  # Last element is the tag\n",
        "                    sentence.append(word)\n",
        "                    label.append(tag)\n",
        "\n",
        "        # Add the last sentence if the file doesn't end with an empty line\n",
        "        if sentence:\n",
        "            sentences.append(sentence)\n",
        "            labels.append(label)\n",
        "\n",
        "    # Print sample to verify format\n",
        "    if sentences:\n",
        "        print(f\"Data format sample (from {file_path}):\")\n",
        "        for i, (token, tag) in enumerate(zip(sentences[0][:5], labels[0][:5])):\n",
        "            print(f\"  {token} -> {tag}\")\n",
        "\n",
        "    return sentences, labels\n",
        "\n",
        "# Read datasets\n",
        "print(f\"Reading training set: {TRAIN_FILE}\")\n",
        "train_sentences, train_labels = read_conll(TRAIN_FILE)\n",
        "print(f\"Reading validation set: {VALID_FILE}\")\n",
        "valid_sentences, valid_labels = read_conll(VALID_FILE)\n",
        "print(f\"Reading test set: {TEST_FILE}\")\n",
        "test_sentences, test_labels = read_conll(TEST_FILE)\n",
        "\n",
        "print(f\"Training set: {len(train_sentences)} sentences\")\n",
        "print(f\"Validation set: {len(valid_sentences)} sentences\")\n",
        "print(f\"Test set: {len(test_sentences)} sentences\")\n",
        "\n",
        "# Display a sample from training data\n",
        "print(\"\\nSample from training data:\")\n",
        "for token, label in zip(train_sentences[0][:10], train_labels[0][:10]):\n",
        "    print(f\"{token} -> {label}\")\n",
        "\n",
        "# Get unique tags\n",
        "unique_tags = sorted(list(set(tag for doc in train_labels for tag in doc)))\n",
        "tag2idx = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "idx2tag = {idx: tag for idx, tag in enumerate(unique_tags)}\n",
        "\n",
        "print(f\"\\nUnique tags: {unique_tags}\")\n",
        "print(f\"Number of unique tags: {len(unique_tags)}\")\n",
        "\n",
        "# NER Dataset class\n",
        "class NERDataset(Dataset):\n",
        "    def __init__(self, sentences, labels, tokenizer, max_len, tag2idx):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        self.tag2idx = tag2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sentence = self.sentences[idx]\n",
        "        word_labels = self.labels[idx]\n",
        "\n",
        "        # Tokenize the sentence\n",
        "        encoding = self.tokenizer(\n",
        "            sentence,\n",
        "            is_split_into_words=True,\n",
        "            return_offsets_mapping=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # Remove batch dimension added by tokenizer\n",
        "        input_ids = encoding['input_ids'].squeeze(0)\n",
        "        attention_mask = encoding['attention_mask'].squeeze(0)\n",
        "        offsets = encoding['offset_mapping'].squeeze(0)\n",
        "\n",
        "        # Create token labels aligned with BERT's WordPiece tokenization\n",
        "        labels = torch.ones(input_ids.shape, dtype=torch.long) * -100  # -100 is ignored by PyTorch's CrossEntropyLoss\n",
        "\n",
        "        # Map word tokens to word pieces (handle subword tokenization)\n",
        "        word_ids = encoding.word_ids()\n",
        "        previous_word_idx = None\n",
        "\n",
        "        for i, word_idx in enumerate(word_ids):\n",
        "            # Skip special tokens\n",
        "            if word_idx is None:\n",
        "                continue\n",
        "\n",
        "            # Only label the first token of a word\n",
        "            if word_idx != previous_word_idx:\n",
        "                # If the word index is within our word_labels range\n",
        "                if word_idx < len(word_labels):\n",
        "                    labels[i] = self.tag2idx.get(word_labels[word_idx], 0)  # Default to 'O' (0) if tag not in tag2idx\n",
        "\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = NERDataset(train_sentences, train_labels, tokenizer, MAX_LEN, tag2idx)\n",
        "valid_dataset = NERDataset(valid_sentences, valid_labels, tokenizer, MAX_LEN, tag2idx)\n",
        "test_dataset = NERDataset(test_sentences, test_labels, tokenizer, MAX_LEN, tag2idx)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Define the BERT + BiLSTM + CRF model\n",
        "class BERTBiLSTMCRF(nn.Module):\n",
        "    def __init__(self, bert_model_name, num_tags, lstm_hidden_dim=768, lstm_layers=2, dropout=0.1):\n",
        "        super(BERTBiLSTMCRF, self).__init__()\n",
        "\n",
        "        # BERT layer\n",
        "        self.bert = AutoModel.from_pretrained(bert_model_name)\n",
        "\n",
        "        # BiLSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=self.bert.config.hidden_size,\n",
        "            hidden_size=lstm_hidden_dim // 2,  # Divide by 2 for bidirectional\n",
        "            num_layers=lstm_layers,\n",
        "            bidirectional=True,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Linear layer for tag prediction\n",
        "        self.hidden2tag = nn.Linear(lstm_hidden_dim, num_tags)\n",
        "\n",
        "        # CRF layer\n",
        "        self.crf = CRF(num_tags, batch_first=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        # Get BERT outputs\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "\n",
        "        # Apply BiLSTM\n",
        "        lstm_output, _ = self.lstm(sequence_output)\n",
        "        lstm_output = self.dropout(lstm_output)\n",
        "\n",
        "        # Apply linear layer to get emissions for CRF\n",
        "        emissions = self.hidden2tag(lstm_output)\n",
        "\n",
        "        # If labels are provided, calculate loss, otherwise return emissions for prediction\n",
        "        if labels is not None:\n",
        "            # Create mask from attention_mask\n",
        "            mask = attention_mask.bool()\n",
        "\n",
        "            # Replace -100 labels with 0 (or any valid tag index) to avoid CRF errors\n",
        "            # CRF will use the mask to ignore these positions\n",
        "            labels_fixed = labels.clone()\n",
        "            labels_fixed[labels == -100] = 0  # Replace with a valid tag index (0)\n",
        "\n",
        "            # Calculate negative log likelihood loss for CRF\n",
        "            log_likelihood = self.crf(emissions, labels_fixed, mask=mask, reduction='mean')\n",
        "            return -log_likelihood\n",
        "        else:\n",
        "            # Decode the best path\n",
        "            mask = attention_mask.bool()\n",
        "            best_tags = self.crf.decode(emissions, mask=mask)\n",
        "            return best_tags\n",
        "\n",
        "# Initialize the model with error handling\n",
        "try:\n",
        "    print(\"Initializing model...\")\n",
        "    model = BERTBiLSTMCRF(MODEL_NAME, len(tag2idx))\n",
        "    model.to(device)\n",
        "    print(f\"Model successfully initialized and moved to {device}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing model: {e}\")\n",
        "    raise\n",
        "\n",
        "# Set up the optimizer with weight decay\n",
        "print(\"Setting up optimizer...\")\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = optim.AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE)\n",
        "print(\"Optimizer configured successfully\")\n",
        "\n",
        "# Training and evaluation functions\n",
        "def train_epoch(model, dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
        "    for batch in progress_bar:\n",
        "        try:\n",
        "            # Clear gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move batch to device\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update total loss\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Update progress bar\n",
        "            progress_bar.set_postfix({\"Loss\": total_loss / (progress_bar.n + 1)})\n",
        "        except Exception as e:\n",
        "            print(f\"Error in batch training: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate(model, dataloader, device, tag2idx, idx2tag):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
        "            try:\n",
        "                # Move batch to device\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                # Get predictions\n",
        "                best_paths = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "                # Move to CPU for processing\n",
        "                input_ids = input_ids.cpu().numpy()\n",
        "                attention_mask = attention_mask.cpu().numpy()\n",
        "                labels = labels.cpu().numpy()\n",
        "\n",
        "                # Process each sequence in the batch\n",
        "                for i, (path, label, mask) in enumerate(zip(best_paths, labels, attention_mask)):\n",
        "                    pred_list = []\n",
        "                    true_list = []\n",
        "\n",
        "                    for j, m in enumerate(mask):\n",
        "                        if m and label[j] != -100:  # Skip padding and subword tokens\n",
        "                            if j < len(path):  # Make sure we don't go out of bounds\n",
        "                                pred_tag = idx2tag.get(path[j], \"O\")  # Default to \"O\" if unknown\n",
        "                                true_tag = idx2tag.get(label[j], \"O\")  # Default to \"O\" if unknown\n",
        "\n",
        "                                pred_list.append(pred_tag)\n",
        "                                true_list.append(true_tag)\n",
        "\n",
        "                    predictions.append(pred_list)\n",
        "                    true_labels.append(true_list)\n",
        "            except Exception as e:\n",
        "                print(f\"Error in evaluation: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "    # Flatten the lists for evaluation (handle empty lists)\n",
        "    flat_preds = []\n",
        "    flat_labels = []\n",
        "\n",
        "    for sublist in predictions:\n",
        "        flat_preds.extend(sublist)\n",
        "\n",
        "    for sublist in true_labels:\n",
        "        flat_labels.extend(sublist)\n",
        "\n",
        "    # Make sure we have equal lengths\n",
        "    min_len = min(len(flat_preds), len(flat_labels))\n",
        "    flat_preds = flat_preds[:min_len]\n",
        "    flat_labels = flat_labels[:min_len]\n",
        "\n",
        "    # Calculate metrics if we have predictions\n",
        "    if len(flat_preds) > 0 and len(flat_labels) > 0:\n",
        "        try:\n",
        "            report = classification_report(flat_labels, flat_preds, digits=4)\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating classification report: {e}\")\n",
        "            report = \"Classification report generation failed\"\n",
        "    else:\n",
        "        report = \"No valid predictions to evaluate\"\n",
        "\n",
        "    return report, predictions, true_labels\n",
        "\n",
        "# Train the model with error handling\n",
        "train_losses = []\n",
        "val_reports = []\n",
        "best_f1 = 0\n",
        "best_model_state = None\n",
        "\n",
        "try:\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\n{'='*20} Epoch {epoch + 1}/{EPOCHS} {'='*20}\")\n",
        "\n",
        "        try:\n",
        "            # Train\n",
        "            print(\"Starting training phase...\")\n",
        "            train_loss = train_epoch(model, train_loader, optimizer, device)\n",
        "            train_losses.append(train_loss)\n",
        "\n",
        "            # Evaluate on validation set\n",
        "            print(\"Starting validation phase...\")\n",
        "            val_report, _, _ = evaluate(model, valid_loader, device, tag2idx, idx2tag)\n",
        "            val_reports.append(val_report)\n",
        "\n",
        "            # Extract F1 score to track best model\n",
        "            try:\n",
        "                # Extract weighted avg F1-score from report\n",
        "                report_lines = val_report.strip().split('\\n')\n",
        "                weighted_avg_line = [line for line in report_lines if 'weighted avg' in line][0]\n",
        "                current_f1 = float(weighted_avg_line.strip().split()[-2])\n",
        "\n",
        "                # Save best model\n",
        "                if current_f1 > best_f1:\n",
        "                    best_f1 = current_f1\n",
        "                    best_model_state = model.state_dict().copy()\n",
        "                    print(f\"New best model saved with F1: {best_f1:.4f}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error extracting F1 score: {e}\")\n",
        "\n",
        "            print(f\"Training Loss: {train_loss:.4f}\")\n",
        "            print(\"Validation Report:\")\n",
        "            print(val_report)\n",
        "            print(\"-\" * 60)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during epoch {epoch + 1}: {e}\")\n",
        "            if epoch > 0:  # Only continue if we have at least one successful epoch\n",
        "                print(\"Continuing to next epoch...\")\n",
        "                continue\n",
        "            else:\n",
        "                raise\n",
        "\n",
        "    # Save the trained model\n",
        "    if best_model_state is not None:\n",
        "        print(\"Saving best model...\")\n",
        "        torch.save(best_model_state, \"bert_bilstm_crf_ner_model.pt\")\n",
        "        # Load best model for final evaluation\n",
        "        model.load_state_dict(best_model_state)\n",
        "    else:\n",
        "        print(\"Saving final model...\")\n",
        "        torch.save(model.state_dict(), \"bert_bilstm_crf_ner_model.pt\")\n",
        "\n",
        "    print(\"Model saved!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error during training: {e}\")\n",
        "    # Save checkpoint if possible\n",
        "    try:\n",
        "        if len(train_losses) > 0:\n",
        "            print(\"Saving model checkpoint from last successful epoch...\")\n",
        "            torch.save(model.state_dict(), \"bert_bilstm_crf_ner_model_checkpoint.pt\")\n",
        "            print(\"Checkpoint saved!\")\n",
        "    except Exception as ce:\n",
        "        print(f\"Could not save checkpoint: {ce}\")\n",
        "\n",
        "# Plot training loss if we have any data\n",
        "if train_losses:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o')\n",
        "    plt.title('Training Loss over Epochs')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.grid(True)\n",
        "    plt.savefig('training_loss.png')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No training loss data to plot\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "try:\n",
        "    print(\"\\nEvaluating on test set...\")\n",
        "    test_report, test_predictions, test_true_labels = evaluate(model, test_loader, device, tag2idx, idx2tag)\n",
        "    print(\"Test Report:\")\n",
        "    print(test_report)\n",
        "except Exception as e:\n",
        "    print(f\"Error during test evaluation: {e}\")\n",
        "    test_predictions = []\n",
        "    test_true_labels = []\n",
        "    test_report = \"Evaluation failed\"\n",
        "\n",
        "# Save the test predictions to a file\n",
        "try:\n",
        "    print(\"\\nSaving test predictions...\")\n",
        "    with open(\"test_predictions.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        for i, (sentence, true_labels, pred_labels) in enumerate(zip(test_sentences, test_true_labels, test_predictions)):\n",
        "            for j, (word, true_label, pred_label) in enumerate(zip(sentence, true_labels, pred_labels)):\n",
        "                f.write(f\"{word} {true_label} {pred_label}\\n\")\n",
        "            f.write(\"\\n\")\n",
        "    print(\"Test predictions saved to test_predictions.txt\")\n",
        "except Exception as e:\n",
        "    print(f\"Error saving predictions: {e}\")\n",
        "    print(\"Trying alternative saving method...\")\n",
        "    try:\n",
        "        with open(\"test_predictions_simple.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "            for i, sentence in enumerate(test_sentences):\n",
        "                for j, word in enumerate(sentence):\n",
        "                    pred_label = \"O\"  # Default prediction if there was an error\n",
        "                    true_label = \"O\"  # Default true label if there was an error\n",
        "\n",
        "                    # Try to get actual predictions if available\n",
        "                    if i < len(test_predictions) and j < len(test_predictions[i]):\n",
        "                        pred_label = test_predictions[i][j]\n",
        "\n",
        "                    # Try to get actual true labels if available\n",
        "                    if i < len(test_true_labels) and j < len(test_true_labels[i]):\n",
        "                        true_label = test_true_labels[i][j]\n",
        "\n",
        "                    f.write(f\"{word} {true_label} {pred_label}\\n\")\n",
        "                f.write(\"\\n\")\n",
        "        print(\"Simplified test predictions saved to test_predictions_simple.txt\")\n",
        "    except Exception as e2:\n",
        "        print(f\"Alternative saving also failed: {e2}\")\n",
        "\n",
        "# Troubleshooting CUDA issues\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TROUBLESHOOTING CUDA ISSUES\")\n",
        "print(\"=\"*80 + \"\\n\")\n",
        "print(\"\"\"\n",
        "If you're encountering CUDA errors like \"device-side assert triggered\" or other GPU-related issues,\n",
        "try the following solutions:\n",
        "\n",
        "1. Set FORCE_CPU = True at the top of this notebook to run everything on CPU\n",
        "   - This is slower but more reliable\n",
        "\n",
        "2. Check CUDA version compatibility:\n",
        "   - Run the following to check your CUDA version:\n",
        "     ```\n",
        "     import torch\n",
        "     print(torch.version.cuda)\n",
        "     ```\n",
        "   - Make sure it's compatible with your PyTorch version\n",
        "\n",
        "3. Check GPU memory:\n",
        "   - You might be running out of GPU memory\n",
        "   - Reduce BATCH_SIZE (e.g., from 16 to 8 or 4)\n",
        "   - Reduce MAX_LEN (e.g., from 128 to 64)\n",
        "\n",
        "4. Environment variables:\n",
        "   - Try setting these environment variables before running:\n",
        "     ```\n",
        "     import os\n",
        "     os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "     ```\n",
        "\n",
        "5. Driver issues:\n",
        "   - Update your NVIDIA drivers\n",
        "   - Restart your runtime or machine\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "# Function to generate predictions for new sentences\n",
        "def predict_entities(model, tokenizer, sentences, tag2idx, idx2tag, device, max_len=128):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "\n",
        "    try:\n",
        "        for sentence in sentences:\n",
        "            # Tokenize\n",
        "            encoding = tokenizer(\n",
        "                sentence,\n",
        "                is_split_into_words=True,\n",
        "                return_offsets_mapping=True,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                max_length=max_len,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Move to device\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "            offsets = encoding['offset_mapping'].squeeze(0).numpy()\n",
        "\n",
        "            # Get predictions\n",
        "            with torch.no_grad():\n",
        "                best_path = model(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
        "\n",
        "            # Convert predictions to tags\n",
        "            pred_tags = []\n",
        "            prev_offset = None\n",
        "            for i, (offset, pred) in enumerate(zip(offsets, best_path)):\n",
        "                # Skip special tokens and padding\n",
        "                if offset[0] == 0 and offset[1] != 0:  # This is the start of a word\n",
        "                    if i < len(best_path):\n",
        "                        pred_tags.append(idx2tag.get(pred, \"O\"))\n",
        "\n",
        "            # Ensure predictions align with original tokens\n",
        "            if len(pred_tags) > len(sentence):\n",
        "                print(f\"Warning: Prediction length mismatch: {len(pred_tags)} vs {len(sentence)}\")\n",
        "                pred_tags = pred_tags[:len(sentence)]\n",
        "\n",
        "            # Pad predictions if necessary\n",
        "            if len(pred_tags) < len(sentence):\n",
        "                pred_tags += ['O'] * (len(sentence) - len(pred_tags))\n",
        "\n",
        "            predictions.append(pred_tags)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during prediction: {e}\")\n",
        "        # Return empty predictions or dummy predictions in case of error\n",
        "        predictions = [['O'] * len(sentence) for sentence in sentences]\n",
        "        print(\"Returning default 'O' predictions due to error\")\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Example of how to use the prediction function\n",
        "example_sentences = [[\"John\", \"lives\", \"in\", \"New\", \"York\", \"and\", \"works\", \"for\", \"Google\"]]\n",
        "try:\n",
        "    print(\"\\nTesting prediction function with example sentence...\")\n",
        "    example_predictions = predict_entities(model, tokenizer, example_sentences, tag2idx, idx2tag, device)\n",
        "\n",
        "    print(\"\\nExample prediction:\")\n",
        "    for sentence, preds in zip(example_sentences, example_predictions):\n",
        "        for token, tag in zip(sentence, preds):\n",
        "            print(f\"{token} -> {tag}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in example prediction: {e}\")\n",
        "\n",
        "# Generate a report\n",
        "print(\"\\nTraining Summary:\")\n",
        "print(f\"Model: BERT + BiLSTM + CRF\")\n",
        "print(f\"Training set size: {len(train_sentences)} sentences\")\n",
        "print(f\"Validation set size: {len(valid_sentences)} sentences\")\n",
        "print(f\"Test set size: {len(test_sentences)} sentences\")\n",
        "print(f\"Number of epochs: {EPOCHS}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "print(f\"Learning rate: {LEARNING_RATE}\")\n",
        "if train_losses:\n",
        "    print(f\"Final training loss: {train_losses[-1]:.4f}\")\n",
        "print(\"\\nTest Results:\")\n",
        "print(test_report)\n",
        "\n",
        "# Create confusion matrix for visualization if possible\n",
        "try:\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    import itertools\n",
        "\n",
        "    flat_preds = [p for sublist in test_predictions for p in sublist]\n",
        "    flat_labels = [l for sublist in test_true_labels for l in sublist]\n",
        "\n",
        "    # Get unique tags from the test data\n",
        "    unique_tags_test = sorted(list(set(flat_labels)))\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(flat_labels, flat_preds, labels=unique_tags_test)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=unique_tags_test, yticklabels=unique_tags_test)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    plt.show()\n",
        "    print(\"Confusion matrix saved to confusion_matrix.png\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating confusion matrix: {e}\")"
      ]
    }
  ]
}